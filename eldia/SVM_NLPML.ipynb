{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4219,"status":"ok","timestamp":1743655031858,"user":{"displayName":"Nekunj Khanna","userId":"09794231376368637110"},"user_tz":-330},"id":"khkox6L75yCh","outputId":"57e5d79e-3c22-4914-f742-afd23d8d0c18"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}],"source":["import pandas as pd\n","import re\n","import numpy as np\n","import pickle\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from imblearn.over_sampling import SMOTE\n","from google.colab import drive\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from google.colab import files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7133,"status":"ok","timestamp":1743655226754,"user":{"displayName":"Nekunj Khanna","userId":"09794231376368637110"},"user_tz":-330},"id":"5U52ibMv5y1f","outputId":"43029b3a-3887-4fee-9c90-d775518675c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Dataset loaded successfully from Google Drive.\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load dataset (Upload manually if needed)\n","file_path = \"/content/drive/My Drive/Suicide_Detection.csv\"\n","try:\n","    df = pd.read_csv(file_path, encoding=\"utf-8\")\n","    print(\"✅ Dataset loaded successfully from Google Drive.\")\n","except FileNotFoundError:\n","    print(\"⚠️ File not found. Please upload manually.\")\n","    uploaded = files.upload()\n","    df = pd.read_csv(next(iter(uploaded)))\n","    print(\"✅ Dataset loaded successfully from upload.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120922,"status":"ok","timestamp":1743655350442,"user":{"displayName":"Nekunj Khanna","userId":"09794231376368637110"},"user_tz":-330},"id":"eXUy7GKQ55Xv","outputId":"647df751-916e-458b-a4a7-c1ef9c767ccb"},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Labels converted to binary format.\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-14-620000182a5d>:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['text'].fillna(\"\", inplace=True)\n"]},{"name":"stdout","output_type":"stream","text":["✅ Text cleaning completed.\n","✅ TF-IDF feature extraction completed. Shape: (232074, 2000)\n","✅ Dataset split into training and testing sets.\n"]}],"source":["# Keep only relevant columns\n","df = df.iloc[:, [1, 2]]\n","df.columns = ['text', 'label']\n","df.dropna(inplace=True)\n","\n","# Convert labels to binary format\n","df['label'] = df['label'].map({'suicide': 1, 'non-suicide': 0})\n","print(\"✅ Labels converted to binary format.\")\n","\n","# Initialize NLP tools\n","stop_words = set(stopwords.words(\"english\"))\n","lemmatizer = WordNetLemmatizer()\n","\n","def clean_text(text):\n","    if not isinstance(text, str):\n","        return \"\"\n","    text = text.lower()\n","    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n","    text = re.sub(r'@\\w+|#\\w+', '', text)  # Remove mentions & hashtags\n","    text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters & punctuation\n","    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n","    return text.strip()\n","\n","# Apply text preprocessing\n","df['text'].fillna(\"\", inplace=True)\n","df['clean_text'] = df['text'].apply(clean_text)\n","print(\"✅ Text cleaning completed.\")\n","\n","# TF-IDF Vectorization\n","vectorizer = TfidfVectorizer(max_features=2000)\n","X = vectorizer.fit_transform(df['clean_text'])\n","y = df['label']\n","print(f\"✅ TF-IDF feature extraction completed. Shape: {X.shape}\")\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","print(\"✅ Dataset split into training and testing sets.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qUgrliCN7Mp8","outputId":"be1fdf18-bccc-4d79-9bab-e1c514fb6304"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training SVM model...\n","SVM model trained successfully.\n","\n"," Test Accuracy: 0.9279\n","\n"," Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.94      0.93     23208\n","           1       0.94      0.92      0.93     23207\n","\n","    accuracy                           0.93     46415\n","   macro avg       0.93      0.93      0.93     46415\n","weighted avg       0.93      0.93      0.93     46415\n","\n","\n"," Confusion Matrix:\n","[[21740  1468]\n"," [ 1878 21329]]\n"]}],"source":["# Train SVM model (Linear kernel for speed)\n","model = SVC(kernel='linear', class_weight='balanced')\n","print(\"Training SVM model...\")\n","model.fit(X_train, y_train)\n","print(\"SVM model trained successfully.\")\n","\n","# Predict on test data\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","test_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\n Test Accuracy: {test_accuracy:.4f}\")\n","print(\"\\n Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","print(\"\\n Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_pred))\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMq0pd9TnG1aJk7G3/yQZ/A"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}